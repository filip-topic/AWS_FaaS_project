# Review Analysis Pipeline - Assignment 3

A serverless application using AWS Lambda functions, S3, and DynamoDB to analyze customer reviews for sentiment, profanity detection, and customer moderation.

## ğŸ—ï¸ Architecture Overview

The application consists of three Lambda functions in a processing pipeline:

1. **Preprocessing Lambda** - Tokenizes, removes stopwords, and lemmatizes review text
2. **Profanity Check Lambda** - Detects bad words and tracks unpolite review counts
3. **Sentiment Analysis Lambda** - Analyzes sentiment and implements customer banning logic

### Data Flow:
```
S3 Upload (reviews-input)
  â†’ Preprocessing Lambda
    â†’ S3 (reviews-preprocessed)
      â†’ Profanity Check Lambda
        â†’ S3 (reviews-checked)
          â†’ Sentiment Analysis Lambda
            â†’ S3 (reviews-processed)
```

## ğŸ“ Project Structure

```
assignment_3/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ lambdas/
â”‚   â”‚   â”œâ”€â”€ preprocessing/          # Text preprocessing Lambda
â”‚   â”‚   â”œâ”€â”€ profanity_check/        # Profanity detection Lambda
â”‚   â”‚   â””â”€â”€ sentiment_analysis/     # Sentiment analysis Lambda
â”‚   â”œâ”€â”€ infrastructure/
â”‚   â”‚   â”œâ”€â”€ setup_localstack_resources.py  # AWS resource setup
â”‚   â”‚   â”œâ”€â”€ build_lambda_packages.py       # Build Lambda deployment packages
â”‚   â”‚   â”œâ”€â”€ deploy_lambdas_python.py       # Deploy Lambda functions
â”‚   â”‚   â””â”€â”€ setup_s3_notifications.py      # S3 event notification setup
â”‚   â””â”€â”€ utils/
â”‚       â”œâ”€â”€ ssm_utils.py            # SSM parameter utilities
â”‚       â”œâ”€â”€ text_preprocessing.py   # Text preprocessing utilities
â”‚       â”œâ”€â”€ sentiment.py            # Sentiment analysis utilities
â”‚       â””â”€â”€ review_analyzer.py      # Review analysis script
â”œâ”€â”€ tests/
â”‚   â”œâ”€â”€ test_integration.py         # Integration tests
â”‚   â”œâ”€â”€ test_utils.py               # Unit tests
â”‚   â””â”€â”€ conftest.py                 # Pytest configuration
â”œâ”€â”€ data/
â”‚   â””â”€â”€ reviews_devset.json         # Review dataset
â”œâ”€â”€ requirements.txt                 # Python dependencies
â”œâ”€â”€ run_analysis.py                  # Review analysis runner
â”œâ”€â”€ show_results.py                  # Results display script
â”œâ”€â”€ setup_and_test.sh                # Full setup and test script
â””â”€â”€ ...
```

## ğŸš€ Quick Start

### 1. Install Dependencies
```bash
pip install -r requirements.txt
```

### 2. Start LocalStack
```bash
localstack start
```

### 3. Full Setup & Test (Recommended)
```bash
chmod +x setup_and_test.sh
./setup_and_test.sh
```

This script will:
- Setup all AWS resources (S3, DynamoDB, SSM)
- Build Lambda deployment packages
- Deploy Lambda functions
- Configure S3 event notifications
- Run setup, manual, unit, and integration tests

### 4. Manual Step-by-Step Setup (Advanced)
```bash
# Setup infrastructure
python src/infrastructure/setup_localstack_resources.py

# Build Lambda packages
python src/infrastructure/build_lambda_packages.py

# Deploy Lambda functions
python src/infrastructure/deploy_lambdas_python.py

# Setup S3 event notifications
python src/infrastructure/setup_s3_notifications.py

# Run tests
python src/tests/test_setup.py
python src/tests/manual_test.py
python -m pytest src/tests/test_utils.py -v
python -m pytest src/tests/test_integration.py -v
```

## ğŸ”§ Infrastructure Setup

### `src/infrastructure/setup_localstack_resources.py`

This script creates and configures all AWS resources needed for the review analysis pipeline in LocalStack:

#### **Resources Created:**

**S3 Buckets:**
- `reviews-input` - Receives new review uploads
- `reviews-preprocessed` - Stores preprocessed reviews (intermediate)
- `reviews-checked` - Stores profanity-checked reviews (intermediate)
- `reviews-processed` - Stores fully processed reviews

**DynamoDB Tables:**
- `review-metadata` - Stores review analysis results (PK: customerId, SK: reviewId)
- `customer-stats` - Tracks customer profanity counts and ban status (PK: customerId)

**SSM Parameters:**
- `/dic2025/a3/bucket/input` - Input bucket name
- `/dic2025/a3/bucket/processed` - Processed bucket name  
- `/dic2025/a3/table/review_metadata` - Review metadata table name
- `/dic2025/a3/table/customer_stats` - Customer stats table name

#### **Features:**
- âœ… **Idempotent**: Can be run multiple times safely
- âœ… **Reset Capability**: Deletes and recreates resources
- âœ… **LocalStack Compatible**: Uses LocalStack endpoints
- âœ… **Parameter Store Integration**: Stores all resource names in SSM

#### **Usage:**
```bash
# Run once to setup resources
python src/infrastructure/setup_localstack_resources.py

# Run again to reset/resetup resources
python src/infrastructure/setup_localstack_resources.py
```

## ğŸ”„ Lambda Deployment & S3 Notifications

- **Build Lambda Packages:**
  - `python src/infrastructure/build_lambda_packages.py`
- **Deploy Lambda Functions:**
  - `python src/infrastructure/deploy_lambdas_python.py`
- **Setup S3 Event Notifications:**
  - `python src/infrastructure/setup_s3_notifications.py`

The notification setup script ensures:
- S3 uploads to `reviews-input` trigger the Preprocessing Lambda
- New files in `reviews-preprocessed` trigger the Profanity Check Lambda
- New files in `reviews-checked` trigger the Sentiment Analysis Lambda
- All required Lambda permissions are set

## ğŸ“Š Review Analysis

### `run_analysis.py` & `src/utils/review_analyzer.py`

Analyzes the `reviews_devset.json` file and provides:

- **Sentiment Distribution**: Positive/Neutral/Negative review counts
- **Profanity Detection**: Reviews containing bad words
- **Customer Moderation**: Banned customers (>3 profane reviews)
- **Detailed Statistics**: Complete analysis with percentages

### Sample Output:
```
ğŸ“Š SENTIMENT ANALYSIS:
   Total Reviews: 78,829
   Positive Reviews: 59,899 (76.0%)
   Neutral Reviews: 15,272 (19.4%)
   Negative Reviews: 3,658 (4.6%)

ğŸš« PROFANITY ANALYSIS:
   Profane Reviews: 5,705 (7.2%)

ğŸ‘¥ CUSTOMER ANALYSIS:
   Banned Customers: 5
```

## ğŸ§ª Testing

### Run All Tests (Recommended)
```bash
./setup_and_test.sh
```

### Run Integration Tests Only
```bash
python -m pytest src/tests/test_integration.py -v
```

### Run Unit Tests Only
```bash
python -m pytest src/tests/test_utils.py -v
```

### Test Coverage:
- âœ… Lambda function triggers
- âœ… Preprocessing pipeline
- âœ… Profanity detection
- âœ… Sentiment analysis
- âœ… Customer banning logic
- âœ… Utility functions
- âœ… S3 event notifications and permissions

## ğŸ” Key Features

- **Serverless Architecture**: AWS Lambda + S3 + DynamoDB
- **Text Processing**: NLTK-based tokenization, stopword removal, lemmatization
- **Sentiment Analysis**: TextBlob-based polarity scoring
- **Profanity Detection**: Custom word list with preprocessing
- **Customer Moderation**: Automatic banning after 3+ profane reviews
- **Parameter Store**: SSM for resource name management
- **LocalStack Support**: Full local development environment
- **Comprehensive Testing**: Integration and unit tests

## ğŸ“ Requirements Met

âœ… **3+ Lambda Functions**: preprocessing, profanity_check, sentiment_analysis  
âœ… **S3 Triggers**: File upload triggers preprocessing  
âœ… **DynamoDB Events**: Review updates trigger sentiment analysis  
âœ… **SSM Integration**: All resource names from Parameter Store  
âœ… **Integration Tests**: Automated pipeline verification  
âœ… **Review Fields**: summary, reviewText, overall analysis  
âœ… **Customer Banning**: >3 unpolite reviews = banned  
âœ… **Intermediate Buckets**: reviews-preprocessed, reviews-checked for pipeline chaining

## ğŸ› ï¸ Development

### Adding New Lambda Functions:
1. Create handler in `src/lambdas/[function_name]/`
2. Use utilities from `src/utils/`
3. Add SSM parameters in setup script
4. Create integration tests

### Modifying Profanity Detection:
Update `PROFANITY_WORDS` set in `src/utils/review_analyzer.py`

### Changing Sentiment Analysis:
Modify `analyze_sentiment()` in `src/utils/sentiment.py`